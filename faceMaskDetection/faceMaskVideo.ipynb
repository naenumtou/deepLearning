{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "faceMaskVideo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xiebH8oW87AScJCpANjBWMQS0IGWu0Bc",
      "authorship_tag": "ABX9TyPw0BqwN2lxb24p0Pc/ZtCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naenumtou/learnTensorFlow/blob/main/faceMaskDetection/faceMaskVideo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OAGPobbGfm2"
      },
      "outputs": [],
      "source": [
        "# Set auto reload\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change working directory\n",
        "%cd /content/drive/My Drive/Colab Notebooks/face_mask_detection"
      ],
      "metadata": {
        "id": "bz-Kzxm8GrY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5555370f-8452-4683-cb38-036c17ecad96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/face_mask_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Checking GPU available\n",
        "if tf.test.gpu_device_name() == '/device:GPU:0':\n",
        "  print('GPU is available')\n",
        "else:\n",
        "  print('GPU is not available')\n",
        "\n",
        "print(f'Tensorflow version: {tf.__version__}')\n",
        "\n",
        "# Config\n",
        "%config InlineBackend.figure_format = 'retina' #Retina display"
      ],
      "metadata": {
        "id": "ShP5w_2YGsvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4575aa-c9f3-476b-f82b-f8784da5819c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n",
            "Tensorflow version: 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "labels = ['Masked', 'No mask']\n",
        "size = 224\n",
        "model = load_model('face_mask.model')"
      ],
      "metadata": {
        "id": "z3xNR0ZDGvcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilise 'facenet' model for face detection\n",
        "faceConfig = 'deploy.prototxt.txt'\n",
        "faceModel = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "# Load 'facenet' model\n",
        "faceNet = cv2.dnn.readNet(\n",
        "    faceConfig,\n",
        "    faceModel\n",
        ")"
      ],
      "metadata": {
        "id": "AuiRPh7EGvaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to predict with video file\n",
        "def videoFaceMask(fileVideo):\n",
        "  cap = cv2.VideoCapture(fileVideo)\n",
        "  w, h  = int(cap.get(3)), int(cap.get(4))\n",
        "  outVideo = cv2.VideoWriter(\n",
        "      'videoResult' + os.path.splitext(fileVideo)[0][-1] + '.mp4',\n",
        "      cv2.VideoWriter_fourcc(*'MP4V'), #With '.mp4' format\n",
        "      30,\n",
        "      (w, h)\n",
        "  )\n",
        "  while True:\n",
        "    ret, frame = cap.read()\n",
        "    if ret == True:\n",
        "      (fh, fw) = frame.shape[:2]\n",
        "      blob = cv2.dnn.blobFromImage(\n",
        "          frame,\n",
        "          1.0,\n",
        "          (300, 300),\n",
        "          (104.0, 177.0, 123.0)\n",
        "      ) #Mean scale\n",
        "      faceNet.setInput(blob)\n",
        "      detections = faceNet.forward()\n",
        "      for i in range(0, detections.shape[2]):\n",
        "        confidence = detections[0, 0, i, 2]\n",
        "        if confidence < 0.5:\n",
        "          continue\n",
        "        box = detections[0, 0, i, 3:7] * np.array([fw, fh, fw, fh])\n",
        "        (startX, startY, endX, endY) = box.astype('int')\n",
        "        (startX, startY) = (max(0, startX), max(0, startY))\n",
        "        (endX, endY) = (min(fw - 1, endX), min(fh - 1, endY))\n",
        "        face = frame[startY:endY, startX:endX][:, :, ::-1]\n",
        "        # Image processing\n",
        "        face = cv2.resize(face, (size, size))\n",
        "        face = np.reshape(face, (1, size, size, 3)) / 255.0\n",
        "        # Model prediction\n",
        "        pred = model.predict(face, batch_size = 64) #Same as training model\n",
        "        label = labels[np.argmax(pred)] #Get label\n",
        "        if label == labels[0]:\n",
        "          color = (0, 255, 0)\n",
        "        else:\n",
        "          color = (0, 0, 255)\n",
        "        cv2.rectangle(\n",
        "            frame,\n",
        "            (startX, startY),\n",
        "            (endX, endY),\n",
        "            color,\n",
        "            3\n",
        "        )\n",
        "        cv2.rectangle(\n",
        "            frame,\n",
        "            (startX, startY - 60),\n",
        "            (endX, startY),\n",
        "            color,\n",
        "            -1\n",
        "        )\n",
        "        cv2.putText(\n",
        "            frame,\n",
        "            label,\n",
        "            (startX + 10, startY - 10),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            1.5,\n",
        "            (255, 255, 255),\n",
        "            2\n",
        "        )\n",
        "        outVideo.write(frame)\n",
        "    else:\n",
        "      break\n",
        "  return"
      ],
      "metadata": {
        "id": "CyU837WzifOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing with video\n",
        "for fileName in sorted(os.listdir(os.getcwd())):\n",
        "  if fileName.endswith('.mp4'):\n",
        "    print(f'Processing: {fileName}')\n",
        "    videoFaceMask(fileName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur1U8Gh2jFz1",
        "outputId": "cc0a8c05-27a0-496c-d913-be6c6bf0deb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: vidoeTest1.mp4\n",
            "Processing: vidoeTest2.mp4\n",
            "Processing: vidoeTest3.mp4\n",
            "Processing: vidoeTest4.mp4\n"
          ]
        }
      ]
    }
  ]
}